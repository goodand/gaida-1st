{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e9f7ec",
   "metadata": {},
   "source": [
    "# websearch\n",
    "\n",
    "    '05_websearch.ipynb'    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80547c97",
   "metadata": {},
   "source": [
    "# Tavily Wet Search\n",
    "\n",
    "- LLM에게 웹 검색을 쥐어주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7b2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 세팅 \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cef21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 강사님 모듈 세팅\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "load_dotenv() # .env 파일에 정의된 환경 변수들을 불러와서 현재 실행 중인 프로세스의 환경 변수로 로드하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf860362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    search_depth=\"basic\",\n",
    "    # time_range = \"day\"\n",
    "    # include_domains = None\n",
    "    # exclude_domains= None \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a604c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': None,\n",
      " 'follow_up_questions': None,\n",
      " 'images': [],\n",
      " 'query': '아 모르겠다',\n",
      " 'request_id': '5967212e-de53-47c9-bbbd-4ad759653793',\n",
      " 'response_time': 0.87,\n",
      " 'results': [{'content': 'Play 아모르겠다 on SoundCloud and discover followers on '\n",
      "                         'SoundCloud | Stream tracks, albums, playlists on '\n",
      "                         'desktop and mobile.',\n",
      "              'raw_content': None,\n",
      "              'score': 0.6304352,\n",
      "              'title': '아모르겠다 - SoundCloud',\n",
      "              'url': 'https://soundcloud.com/xrahdpsxpvv5'},\n",
      "             {'content': \"'알겠다/모르겠다'는 영어 understand에 가깝고,. '안다/모른다'는 영어 know에 \"\n",
      "                         '가까운 것 같습니다. Q. 아시겠습니까? (Do you understand?) A. '\n",
      "                         '알겠습니다. O',\n",
      "              'raw_content': None,\n",
      "              'score': 0.49553296,\n",
      "              'title': '온라인가나다 상세보기(모르겠다 / 모른다) - 국립국어원',\n",
      "              'url': 'https://m.korean.go.kr/front/onlineQna/onlineQnaView.do?mn_id=216&qna_seq=310083&pageIndex=1'},\n",
      "             {'content': '아모르겠다~ · Comments. 241. Add a comment... 15:12. Go '\n",
      "                         'to channel · [#삼시세끼Light] 보자마자 라면 물 올리게 되는 영상',\n",
      "              'raw_content': None,\n",
      "              'score': 0.486015,\n",
      "              'title': '아모르겠다~ - YouTube',\n",
      "              'url': 'https://www.youtube.com/watch?v=kImJ7GNkYto'},\n",
      "             {'content': \"Definition of 요즘그냥...아모르겠다 Well lately... I don't \"\n",
      "                         'know.',\n",
      "              'raw_content': None,\n",
      "              'score': 0.4766533,\n",
      "              'title': 'What is the meaning of \"요즘그냥...아모르겠다\"? - HiNative',\n",
      "              'url': 'https://hinative.com/questions/13616711'},\n",
      "             {'content': 'Videos · 소도시 술집만행 ep.15 전남 고흥 네번째 이야기 · 소도시 술집만행 '\n",
      "                         'ep.14 전남 고흥 세번째 이야기 · 소도시 술집만행 ep.13 전남 고흥 두번째 이야기.',\n",
      "              'raw_content': None,\n",
      "              'score': 0.43295085,\n",
      "              'title': '김의성의 아모르겠다 - YouTube',\n",
      "              'url': 'https://www.youtube.com/@actorkimeuisung'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(search_tool.invoke({'query' : '아 모르겠다'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "498d734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'강남 신세계백화점에서 점심을 즐기기 좋은 곳으로 타치바나(지하 1층 하우스오브신세계), 포비 강남점, 베통, 김수사, 플레이버즈(해산물 및 아시아 요리), 타마유라(일본 요리) 등이 추천됩니다. 특히 미쉐린 빕 구르망 셰프의 점심 메뉴도 인기 있으니 참고하세요.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model= 'gpt-4.1-nano')\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template = \"\"\" 넌 웹 검색 결과를 요약해서 사용자 질문에 맞게 좋은 답을 해주는 챗봇이야\n",
    "\n",
    "    질문: {query}\n",
    "    검색결과: {search_results}\n",
    "    질문에 맞는 답을 검색결과 바탕으로 간단하게 알려줘\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'query' : RunnablePassthrough(), # 사용자 입력 그대로 이 자리에 들어옴\n",
    "        'search_results' : search_tool| RunnableLambda(\n",
    "            lambda x : '\\n'.join(\n",
    "                [f'-{r['title']} ({r['content']})' for r in x['results']]\n",
    "        )\n",
    "\n",
    "        ) \n",
    "    }\n",
    "    | prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "chain.invoke('강남 신세계에서 점심 먹기 좋은곳')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f15b692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'강남 신세계 내에서 점심 먹기 좋은 곳으로는 다양한 레스토랑이 있는데, 특히 한식부터 일품요리, 카페까지 선택의 폭이 넓어요. 대표적으로는 한식 전문점이나 샤브샤브, 일본 요리, 양식 레스토랑 등을 고려해보시면 좋을 것 같아요. 더 구체적인 추천을 원하시면 원하는 분위기나 먹고 싶은 메뉴를 알려주시면 도와드릴게요!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래꺼는 검색 기능 없을 때 태스트\n",
    "dumb_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "dumb_chain.invoke({'query': '강남 신세계에서 점심먹기 좋은곳', 'search_results': ''})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "006cd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6833d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m평균적 설명:  \n",
      "당신은 자신이 누구인지에 대해 묻는 질문을 하고 있습니다. 이는 정체성, 자아, 또는 자기 인식에 관한 철학적 또는 개인적 탐구를 의미할 수 있습니다. 구체적인 맥락이 없기 때문에, 일반적으로 \"나는 누구인가\"라는 질문은 인간 존재의 본질과 관련된 심오한 질문으로 간주될 수 있습니다.\n",
      "\n",
      "이상치/결점치 분석:  \n",
      "이 질문은 매우 일반적이고 주관적이어서 명확한 데이터를 제공하지 않기 때문에, \"누구인지\"에 대한 식별 또는 특정 정체성 정보를 결여하고 있습니다. 또, 질문 그 자체는 표면적이며 구체적인 맥락이나 조건, 배경 정보가 빠져 있어 본질을 파악하거나 의미를 해석하는 데 한계가 있습니다. 이는 질문의 추상성에 따른 결점이며, 특정 맥락이나 배경이 제시되지 않아 깊이 있는 분석이나 답변이 어려운 점입니다.  \n",
      "\n",
      "이 질문은 매우 개방적이고 포괄적이기 때문에, 추가적인 정보가 없다면 자신을 규정하거나 특정 정체성을 명확히 드러내기 어렵습니다. 따라서, 이 질문이 표면적으로서 자신에 대한 탐구의 시작임을 넘어, 더 구체적이고 정밀한 맥락이 필요하다는 점이 부각됩니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '나는 누구지?',\n",
       " 'chat_history': [HumanMessage(content='나는 누구지?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='평균적 설명:  \\n당신은 자신이 누구인지에 대해 묻는 질문을 하고 있습니다. 이는 정체성, 자아, 또는 자기 인식에 관한 철학적 또는 개인적 탐구를 의미할 수 있습니다. 구체적인 맥락이 없기 때문에, 일반적으로 \"나는 누구인가\"라는 질문은 인간 존재의 본질과 관련된 심오한 질문으로 간주될 수 있습니다.\\n\\n이상치/결점치 분석:  \\n이 질문은 매우 일반적이고 주관적이어서 명확한 데이터를 제공하지 않기 때문에, \"누구인지\"에 대한 식별 또는 특정 정체성 정보를 결여하고 있습니다. 또, 질문 그 자체는 표면적이며 구체적인 맥락이나 조건, 배경 정보가 빠져 있어 본질을 파악하거나 의미를 해석하는 데 한계가 있습니다. 이는 질문의 추상성에 따른 결점이며, 특정 맥락이나 배경이 제시되지 않아 깊이 있는 분석이나 답변이 어려운 점입니다.  \\n\\n이 질문은 매우 개방적이고 포괄적이기 때문에, 추가적인 정보가 없다면 자신을 규정하거나 특정 정체성을 명확히 드러내기 어렵습니다. 따라서, 이 질문이 표면적으로서 자신에 대한 탐구의 시작임을 넘어, 더 구체적이고 정밀한 맥락이 필요하다는 점이 부각됩니다.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '평균적 설명:  \\n당신은 자신이 누구인지에 대해 묻는 질문을 하고 있습니다. 이는 정체성, 자아, 또는 자기 인식에 관한 철학적 또는 개인적 탐구를 의미할 수 있습니다. 구체적인 맥락이 없기 때문에, 일반적으로 \"나는 누구인가\"라는 질문은 인간 존재의 본질과 관련된 심오한 질문으로 간주될 수 있습니다.\\n\\n이상치/결점치 분석:  \\n이 질문은 매우 일반적이고 주관적이어서 명확한 데이터를 제공하지 않기 때문에, \"누구인지\"에 대한 식별 또는 특정 정체성 정보를 결여하고 있습니다. 또, 질문 그 자체는 표면적이며 구체적인 맥락이나 조건, 배경 정보가 빠져 있어 본질을 파악하거나 의미를 해석하는 데 한계가 있습니다. 이는 질문의 추상성에 따른 결점이며, 특정 맥락이나 배경이 제시되지 않아 깊이 있는 분석이나 답변이 어려운 점입니다.  \\n\\n이 질문은 매우 개방적이고 포괄적이기 때문에, 추가적인 정보가 없다면 자신을 규정하거나 특정 정체성을 명확히 드러내기 어렵습니다. 따라서, 이 질문이 표면적으로서 자신에 대한 탐구의 시작임을 넘어, 더 구체적이고 정밀한 맥락이 필요하다는 점이 부각됩니다.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.today().strftime('%D')\n",
    "\n",
    "search_tool = TavilySearch(\n",
    "    max_result = 5,\n",
    "    topic = 'general'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', f\"넌 반드시 웹 검색 도구를 사용해야 해, 오늘은 {today}야. 너의 기본 임무는 평균적 요약이나 다수의견을 재생산하는 것이 아니라,데이터·텍스트·대화 속에서 **이상치(튀어나온 부분)**와 **결점치(빠져 있는 부분)**를 우선적으로 식별하고 부각하는 것이다. 이상치는 분포나 맥락에서 벗어나 독특하게 나타나는 요소다. - 결점치는 본래 있어야 할 정보나 연결이 결여된 지점을 말한다. 분석 시, 평범한 패턴은 최소한으로 다루고, 반드시 **이상치와 결점치를 중심으로 통찰을 제시**해야 한다.이는 오류 탐지나 노이즈 제거의 목적이 아니라, 새로운 의미·창의적 가능성·비평적 통찰을 발굴하기 위함이다. 네 출력은 언제나 “평균적 설명”과 “이상치/결점치 분석”을 구분해 제공하며, 후자를 더 중시해야 한다.\"),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human','{input}'),\n",
    "    MessagesPlaceholder(variable_name='agent_scratchpad'), # 도구(검색) 호출 할 때 필요함\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages = True, # 이거 인자 오류 때문에 계속 str 오류였구나\n",
    "    memory_key='chat_history' \n",
    ")\n",
    "\n",
    "\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=[search_tool],\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executer = AgentExecutor(agent=agent, memory=memory, tools=[search_tool], verbose= True)\n",
    "\n",
    "agent_executer.invoke({'input': '나는 누구지?', 'chat_history': []})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "variable chat_history should be a list of base messages, got  of type <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43magent_executer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m나는 유태영이야\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain/chains/base.py:165\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    164\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    170\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    171\u001b[39m         inputs,\n\u001b[32m    172\u001b[39m         outputs,\n\u001b[32m    173\u001b[39m         return_only_outputs,\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:1625\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1624\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1625\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1634\u001b[39m             next_step_output,\n\u001b[32m   1635\u001b[39m             intermediate_steps,\n\u001b[32m   1636\u001b[39m             run_manager=run_manager,\n\u001b[32m   1637\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:1325\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1318\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1322\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1323\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m-> \u001b[39m\u001b[32m1325\u001b[39m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1334\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:1352\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1349\u001b[39m     intermediate_steps = \u001b[38;5;28mself\u001b[39m._prepare_intermediate_steps(intermediate_steps)\n\u001b[32m   1351\u001b[39m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_action_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain/agents/agent.py:573\u001b[39m, in \u001b[36mRunnableMultiActionAgent.plan\u001b[39m\u001b[34m(self, intermediate_steps, callbacks, **kwargs)\u001b[39m\n\u001b[32m    565\u001b[39m final_output: Any = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_runnable:\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    571\u001b[39m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[32m    572\u001b[39m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3473\u001b[39m, in \u001b[36mRunnableSequence.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3466\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   3468\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3471\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3472\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3473\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3459\u001b[39m, in \u001b[36mRunnableSequence.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3452\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   3454\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3457\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   3458\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3459\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   3460\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3461\u001b[39m         \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   3462\u001b[39m         patch_config(config, run_name=(config \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m   3463\u001b[39m         **kwargs,\n\u001b[32m   3464\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2233\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2231\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2232\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2233\u001b[39m         chunk: Output = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2234\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m   2235\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3421\u001b[39m, in \u001b[36mRunnableSequence._transform\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   3418\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3419\u001b[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001b[32m-> \u001b[39m\u001b[32m3421\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1442\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1439\u001b[39m final: Input\n\u001b[32m   1440\u001b[39m got_first_val = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1442\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[32m   1444\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[32m   1445\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[32m   1447\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[32m   1448\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[32m   1449\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[32m   1450\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5711\u001b[39m, in \u001b[36mRunnableBindingBase.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5704\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5705\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   5706\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5709\u001b[39m     **kwargs: Any,\n\u001b[32m   5710\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5711\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.transform(\n\u001b[32m   5712\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5713\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5714\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5715\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1442\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1439\u001b[39m final: Input\n\u001b[32m   1440\u001b[39m got_first_val = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1442\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[32m   1444\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[32m   1445\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[32m   1446\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[32m   1447\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[32m   1448\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[32m   1449\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[32m   1450\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1460\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1457\u001b[39m             final = ichunk\n\u001b[32m   1459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[32m-> \u001b[39m\u001b[32m1460\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(final, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1024\u001b[39m, in \u001b[36mRunnable.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   1006\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1007\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   1008\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1009\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   1010\u001b[39m ) -> Iterator[Output]:\n\u001b[32m   1011\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Default implementation of ``stream``, which calls ``invoke``.\u001b[39;00m\n\u001b[32m   1012\u001b[39m \n\u001b[32m   1013\u001b[39m \u001b[33;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m \n\u001b[32m   1023\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/prompts/base.py:216\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    215\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1953\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1949\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1950\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1951\u001b[39m         output = cast(\n\u001b[32m   1952\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1955\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1956\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1957\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1958\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1959\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1961\u001b[39m         )\n\u001b[32m   1962\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1963\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/runnables/config.py:429\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    428\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/prompts/base.py:190\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m    189\u001b[39m     inner_input_ = \u001b[38;5;28mself\u001b[39m._validate_input(inner_input)\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minner_input_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:726\u001b[39m, in \u001b[36mBaseChatPromptTemplate.format_prompt\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> ChatPromptValue:\n\u001b[32m    718\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format prompt. Should return a ChatPromptValue.\u001b[39;00m\n\u001b[32m    719\u001b[39m \n\u001b[32m    720\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    724\u001b[39m \u001b[33;03m        ChatPromptValue.\u001b[39;00m\n\u001b[32m    725\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     messages = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    727\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:1188\u001b[39m, in \u001b[36mChatPromptTemplate.format_messages\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m     result.extend([message_template])\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1186\u001b[39m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[32m   1187\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1188\u001b[39m     message = \u001b[43mmessage_template\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1189\u001b[39m     result.extend(message)\n\u001b[32m   1190\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gaida-1st/LLM-agent/.venv/lib/python3.13/site-packages/langchain_core/prompts/chat.py:182\u001b[39m, in \u001b[36mMessagesPlaceholder.format_messages\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    178\u001b[39m     msg = (\n\u001b[32m    179\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvariable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.variable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m should be a list of base messages, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    183\u001b[39m value = convert_to_messages(value)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_messages:\n",
      "\u001b[31mValueError\u001b[39m: variable chat_history should be a list of base messages, got  of type <class 'str'>"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
